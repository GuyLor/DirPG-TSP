{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder():\n",
    "    def __call__(self, inputs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          inputs: [batch_size, num_nodes, node_dim] tensor\n",
    "        Returns:\n",
    "          [batch_size, num_nodes, embedding_dim] tensor\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "class Decoder():\n",
    "    def __call__(self, encoder_output, context_node_id, visited_mask):\n",
    "        \"\"\"Looks up embedding for context node, then does masked attention over encoder outputs.\n",
    "        \n",
    "        Result is log probs over next nodes.\n",
    "        \n",
    "        Args:\n",
    "          inputs: [batch_size, num_nodes, embedding_dim]\n",
    "          ...\n",
    "          \n",
    "        Returns:\n",
    "          [batch_size, num_nodes] tensor of log probs with masking applied.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class BatchedState():\n",
    "    def __init__():\n",
    "        \"\"\"\n",
    "        Should mirror the StateTSP of \"attention learn how to solve routing problems\"\n",
    "        \"\"\"\n",
    "\n",
    "class BatchedGraphs():\n",
    "    def __init__(self, edge_costs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          edge_costs: [batch_size, num_edges, 2]\n",
    "        \"\"\"\n",
    "        self._edge_costs = edge_costs\n",
    "        \n",
    "        \n",
    "class BatchedQueues():\n",
    "    def __init__(self, batched_graphs):\n",
    "        pass\n",
    "    \n",
    "    def pop_batch(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate random edge costs\n",
    "num_nodes_per_graph = 20\n",
    "num_batches = 100\n",
    "batch_size = 10\n",
    "\n",
    "# C++\n",
    "graphs = BatchedGraphs(edge_costs)\n",
    "graphs.pre_sort_edges()\n",
    "\n",
    "# Python / GPU\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()   \n",
    "node_hiddens = Encoder(graphs)\n",
    "\n",
    "# C++\n",
    "queues = BatchedQueues(graphs)\n",
    "\n",
    "# Python\n",
    "for _ in range(num_batches):  # while queues not empty\n",
    "    # C++\n",
    "    current_nodes = queues.pop_batch()\n",
    "    \n",
    "    # C++ -> Python -- small amount of memory\n",
    "    # current_nodes:\n",
    "    #  * prefixes / visited masks\n",
    "    #  * context nodes (TODO: what does that mean?)\n",
    "    \n",
    "    # CPU -> GPU\n",
    "    # * current_nodes\n",
    "    # NOT node_hiddens (should already be on GPU, so no cost to send in inner loop)\n",
    "    \n",
    "    # Python / GPU\n",
    "    action_log_probs = decoder(node_hiddens, current_nodes)  # [batch, num_nodes] child log probs\n",
    "    \n",
    "    # ?? (probably python)\n",
    "    special_actions = sample(action_log_probs)\n",
    "\n",
    "    # GPU -> CPU\n",
    "    # * special children [batch_size] of ints\n",
    "\n",
    "    # ok to do on python CPU\n",
    "    other_actions = get_other_actions(current_nodes, special_actions)\n",
    "    \n",
    "    # Convert actions to nodes\n",
    "    # python or C++?\n",
    "    \n",
    "    # Python -> C++ -- no huge tensors\n",
    "    # * batch of prefixes (though maybe this can live in C++ already)\n",
    "    # * special children\n",
    "    # * other children\n",
    "    \n",
    "    # C++\n",
    "    # get batch of truncated gumbels\n",
    "    # [batch] tensors of costs\n",
    "    special_spanning_tree_costs = graphs.spanning_tree_cost(current_nodes.prefixes, special_children)\n",
    "    # [batch] tensors of costs\n",
    "    other_spanning_tree_costs = graphs.spanning_tree_cost(current_nodes.prefixes, other_children)\n",
    "    \n",
    "    # C++\n",
    "    # missing: first node, next possible actions\n",
    "    queues.add(special_children, special_spanning_tree_costs, special_gumbels)\n",
    "    queues.add(other_children, other_spanning_tree_costs, other_gumbels)\n",
    "   \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import kruskals_cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heap = kruskals_cpp.Heap()\n",
    "node1 = kruskals_cpp.HeapNode(1.1, 3,torch.ones(10,1, dtype=torch.long))\n",
    "heap.push(node1)\n",
    "node2 = kruskals_cpp.HeapNode(3.4, 2, torch.zeros(10,1, dtype=torch.long))\n",
    "heap.push(node2)\n",
    "node3 = kruskals_cpp.HeapNode(3.4, 2,torch.ones(10,1, dtype=torch.long))\n",
    "heap.push(node3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = heap.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bc72e9cb46ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "parent.ids = torch.ones(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
